#!/usr/bin/python
# -*- coding: UTF-8 -*-#
#
# Copyright (C) 2010 Carlos III University of Madrid
# This file is part of the Adagio: Agile Distributed Authoring Toolkit

# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor
# Boston, MA  02110-1301, USA.
#
# Author: Abelardo Pardo (abelardo.pardo@uc3m.es)
#
import sys, os, getopt, locale, codecs, hashlib, re

# Fix the output encoding when redirecting stdout
if sys.stdout.encoding is None:
    (lang, enc) = locale.getdefaultlocale()
    if enc is not None:
        (e, d, sr, sw) = codecs.lookup(enc)
        # sw will encode Unicode data to the locale-specific character set.
        sys.stdout = sw(sys.stdout)

# Import the Adagio package
_dirName = os.path.dirname(__file__)
_dirName = os.path.abspath(os.path.join(_dirName, '..'))
sys.path.insert(0, _dirName)
sys.path.insert(0, os.path.join(_dirName, 'pla'))

import pla, pla.mysql

def main():
    """
    Script that processes a file obtained with the following SQL command over a
    .LRN database:

    COPY (select * from forums_messages where forum_id in (60923, 71691)) TO
    file.txt;

    where 60923 and 71691 are the forum_ids for a set of forums. The file has
    the following columns:

     0- message_id (key)
     1- forum_id *
     2- subject 
     3- content
     4- user_id *
     5- posting_date *
     6- state 
     7- format
     8- parent_id
     9- open_p
    10- tree_sortkey
    11- max_child_sortkey
    12- last_child_post
    13- reply_count
    14- approved_reply_count
    15- last_poster 

    And inserts in the database the corresponding events with the following
    strategy. For each post the following elements are created:

    Event: id (fixed), 
           datetime from the post, 
           name = 'dotLRN_forum_post'
           sharingLevel = NULL (not given)
           sessionfk = ???

    (mimetype and name are NULL)

    Relatedentity 1 (portal): 
      id (generated by the hash)
      reference:
      type:

    Relatedentity 1 (person): 
      id (generated by the hash)
      reference:
      type:

    Relatedentity 1 (forum): 
      id (generated by the hash)
      mimetype:
      type:

    Relatedentity 1 (community): 
      id (generated by the hash)
      reference:
      type:

    Relatedentity 1 (message): 
      id (generated by the hash)
      reference:
      type:

    Relatedentity 1 (thread): 
      id (generated by the hash)
      reference:
      type:

    EventRelatedentity (one for each entity)


    Script invokation

    script [options] UserNameTo.LRNID.csv Forum_dump

    Options :

    -c URL. The URL of the context in which the events where caught

    -h hostname For DB connection (default localhost)
    
    -u username For DB connection
  
    -p passwd For DB connection (default is empty)
    
    -d dbname For DB connection

    -n When given, the queries are printed instead of executed

    -s char Character to use as separator in the CSV (default ';')

    Example:

    dotlrnforumToRDB.py -u user -p passwd -d dbname UserTo.LRNID.csv ForumDum.txt
    """

    # Default value for the options
    contextURL = ''
    hostname = 'localhost'
    username = None
    passwd = ''
    dbname = None
    dryRun = False
    separator = ','

    # Swallow the options
    try:
        opts, args = getopt.getopt(sys.argv[1:], "c:h:u:p:d:ns:", [])
    except getopt.GetoptError, e:
        print str(e)
        sys.exit(2)

    # Parse the options
    for optstr, value in opts:
        # Conext URL
        if optstr == "-c":
            contextURL = value

        # DB Name
        elif optstr == "-d":
            dbname = value

        # Hostname
        elif optstr == "-h":
            hostname = value

        # Dry run
        elif optstr == "-n":
            dryRun = True

        # Passwd
        elif optstr == "-p":
            passwd = value

        # Separator
        elif optstr == "-s":
            separator = value
        # Username
        elif optstr == "-u":
            username = value

    # Last two arguments must be existing files
    if len(args) != 2:
        print 'The script needs two file names as last arguments.'
        print main.__doc__
        sys.exit(1)
    if (not os.path.isfile(args[0])) or (not os.path.isfile(args[1])):
        print  'The last two arguments are not existing files.'
        print main.__doc__
        sys.exit(1)

    # Context URL must be non empty
    if contextURL == '':
        print 'Use option -c URL to provide a context URL'
        sys.exit(1)

    # Swallow the CSV with Username,dotlrnID
    userIdToName = {}
    for line in codecs.open(args[0], 'r'):
        # Skip lines starting with #
        if line[0] == '#':
            continue
        
        (userName, userId) = line[:-1].split(separator)
    
        userIdToName[userId] = userName

    # Parse the file with the forum data
    forumData = {}
    crap = 0
    delims = []
    data = []
    forumSet = {}
    personSet = {}
    for line in codecs.open(args[1], 'r'):
        line = line[:-1]
        
        # Detect the format line
        if re.match('^(\-+\+)+\-+$', line):
            prev = 0
            idx = 0
            end = len(line) - 1
            while True:
                point = line.find('+', idx, end)
                if point == -1:
                    break
                delims.append((prev, point))
                prev = point
                idx = point + 1
            delims.append((prev, end + 1))

            # Keep processing the next line
            continue
        
        # If the delimiter line has not been found, keep swallowing lines
        if delims == []:
            continue

        # If the line does not have all the fields, skip it
        if len(line) <= delims[-1][0]:
            continue

        # If we are in a line with | and data, new row detected
        if next((y for (x, y) in delims[:-1] if line[y] == '|'), None) and \
                data != []:

            # The userID needs to be remapped
            data[4] = userIdToName[data[4]]

            forumData[data[0]] = (data[1], data[3][:2047], data[4], 
                                  data[5], data[8])
            # If the forum does not have its hexdigest, create it
            if forumSet.get(data[1]) == None:
                forumSet[data[1]] = getHexDigest('forum_' + data[1])

            # If the person does not have its hexdigest, create it
            if personSet.get(data[4]) == None:
                personSet[data[4]] = getHexDigest(data[4])
            data = []

        # Split the line into fields separated by | 
        data = splitLine(line, delims, data)

    print '/* Processing', len(forumData.keys()), ' forum posts*/'

    # Connect to the DB
    cursor = None
    try:
        pla.mysql.connect(hostname, username, passwd, dbname)
    except Exception, e:
        print 'Unable to connect with the database'
        print str(e)
        sys.exit(1)
    cursor = pla.mysql.cursorObj

    # Queries
    insertEvent = "INSERT INTO Event (datetime, name) VALUES (%s, %s)"
    insertEventRelatedentity = """
        INSERT INTO EventRelatedentity (role, eventid, relatedentityid) 
        VALUES (%s, %s, %s)
        """
    insertRelatedentity = """
        INSERT INTO Relatedentity (id, reference, type) VALUES
        (%s, %s, %s, %s) ON DUPLICATE KEY UPDATE
        """

    # Insert some common entities

    # context URL
    contextEntity = findOrAddEntity([(getHexDigest(contextURL), contextURL, 
                                      'portal')], 
                                    cursor, insertRelatedentity, dryRun)

    # Insert the forum entities
    forumIDs = findOrAddEntity([(fdig, fid, 'forum') 
                                for (fid, fdig) in forumSet.items()],
                               cursor, insertRelatedentity, dryRun)
    # The forumIDs need to be reassigned in case some of them already existed
    forumSet.update(zip(forumSet.keys(), forumIDs))

    # Insert the person entities
    personIDs = findOrAddEntity([(pdig, pid, 'person')
                                 for (pid, pdig) in personSet.items()],
                                cursor, insertRelatedentity, dryRun)
    # The personIDs need to reassigned in case some of them already existed
    personSet.update(zip(personSet.keys(), personIDs))
    
    # NEED TO CREATE COMMUNITY ID BASED ON THE FORUM. BUT THIS CORRESPONDENCE
    # HAS TO BE GIVEN FROM OUTSIDE

    print forumSet.keys()

    # Loop over all the forum posts and generate the proper entries
    for (m_id, fields) in sorted(forumData.items()):
        pass

    # Done. Close connection
    pla.mysql.disconnect()

def splitLine(line, delims, data = None):
    """
    Delims are pairs (a, b) delimiting the fields in the line. Chop the line and
    create a list with the fields. If the data is given and the line contains
    ':' the value is added (normalized) to the field.
    """
    
    # If no data is given, set it to empty
    if data == None:
        data = []

    for idx in range(0, len(delims)):
        # Get the limits
        (beg, end) = delims[idx]
        
        fieldValue = line[beg + 1:end - 1].strip()

        # Replace \r by \n
        fieldValue = fieldValue.replace('\\r', '\n')

        if (beg > 0 and line[beg] == '|') or (end < len(line) and line[end] == '|'):
            data.insert(idx, fieldValue)
        elif line[beg] == ':':
            if fieldValue != '':
                data[idx] += fieldValue

    return data

def findOrAddEntity(valueTupleList, cursor, query, dryRun):
    """
    Find or add entities in the list of tuples (digest, reference and type) in
    valueTupleList. If not found, insert them.  Return list of IDs
    """

    findQuery = """
        SELECT id FROM Relatedentity 
        WHERE reference = %s AND type = %s
        """
    result = []
    for (dgst, ref, etype) in valueTupleList:
        executeTransaction(cursor, findQuery, (ref, etype), False)

        # If the cursor has one row, hit, return the obtained ID
        if cursor.rowcount == 1:
            print 'HIT', ref, etype
            result.append(cursor.fetchone()[0])
            continue
        
        # Proceed to insert values
        executeTransaction(cursor, query, (dgst, ref, etype), dryRun)
        result.append(dgst)

    return result

def executeTransaction(cursor, query, values, dryRun):
    """
    Push the transction, and if failure, retract it and bomb out. If values is a
    list, the executemany function is used.
    """

    # Just kidding, dump
    if dryRun:
        print query, values
        return

    # Go for it
    try:
        if type(values) == list:
            cursor.executemany(query, values)
        else:
            cursor.execute(query, values)
        pla.mysql.dbconnection.commit()
    except:
        print '/* Error executing', query, '*/'
        sys.exit(1)

    return

def getHexDigest(item):
    """
    Given an item, create an hex digest
    """
    m = hashlib.sha1()
    m.update(str(item))
    return m.hexdigest()

if __name__ == "__main__":
    main()
